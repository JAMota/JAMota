# Data Engineer

#### Technical Skills: Python, SAP BI, Power BI, PL/SQ, R, Apache Kafka

## Work Experience
**Freelance Data Analytics Consultant (_September 2023 - March 2024_)**
- Developed dynamic Excel dashboards for financial analysis and market research, enhancing data accessibility and analysis efficiency by 30%. This initiative was pivotal in transforming the way clients approached data-driven decision-making, leading to a 40% increase in data utilization and a 35% improvement in decision-making efficiency.
- Established strong client relationships by actively engaging with senior management to understand their specific data needs and tailored dashboards to meet these needs, enhancing data management efficiency by 25%.
- Utilized advanced Excel techniques and conditional formatting to develop dynamic dashboards, showcasing my proficiency in programming and data visualization. This technical expertise was instrumental in enhancing data management efficiency by up to 25% for certain clients, facilitating quicker decision-making processes.

**Portfolio Analyst @ European Investment Bank (_March 2020 - August 2020_)**
- Led the development of dynamic dashboards in SAP Business Intelligence, reducing project assessment time by 30% and enhancing team efficiency. This initiative not only expedited the project assessment process but also reduced workload, enabling the team to consistently meet targets and standards while maintaining operational efficiency.
- Achieved a 25% increase in project evaluation and documentation efficiency. This achievement was crucial in mitigating the impact of team member absence and providing a solid foundation for future reference and development.
- Collaborated closely with the IT support team and other departments to integrate data into existing systems, showcasing my ability to work effectively in a team-oriented environment. This collaboration was instrumental in delivering high-quality output against stated project objectives and meeting tight deadlines.
- During my tenure at the EIB, I honed my skills in data integration, data warehousing, gaining proficiency in tools such as SQL, and SAP Business Intelligence. This experience not only enriched my technical skill set but also equipped me with the ability to develop and deliver leading-edge solutions to industry clients.



**Tech Support Systems Analyst @ CPS (_February 2022 - July 2022_)**
- Delivered comprehensive technical support services to our valued clients, resolving a wide range of IT-related issues, encompassing hardware, software, server, and network challenges. This role not only showcased my technical expertise but also my ability to troubleshoot and resolve complex problems efficiently.
- Maintained and optimized clients' systems, servers, and networks, maximizing performance and security. Implemented best practices in IT security and data protection, ensuring the integrity and confidentiality of client data. This proactive approach to security was instrumental in building trust and maintaining long-term client relationships.
- Meticulously documented support activities, allowing for effective tracking and transparency. This attention to detail ensured that clients were always informed about the status of their issues and the steps taken to resolve them, fostering a culture of accountability and reliability.


## Education					       		
- M.S., Data Science and Statistics	| University of Exeter (_December 2023_)	 			        		
- B.S., Computer Science | Polytechnic of Leiria (_July 2022_)

## Projects
### Queueing theory for analysis and improvement of data pipelines

[Master Thesis](https://github.com/JAMota/Applied-Data-Science-and-Statistics/tree/main/Thesis)

- For my master thesis, I developed a complex data pipeline from scratch, employing queueing theory for analysis. I utilized an SQLite database to securely store all generated data, ensuring efficient retrieval and manipulation of the data.
- To facilitate data flow across various servers, I implemented a multi-step data pipeline using Apache Kafka in the Azure cloud. This allowed for seamless data generation based on the data collection at each server, achieved through Python scripting.
- Following the ETL (Extract, Transform, Load) practice, I extracted, wrangled, normalized, and cleaned all data from each step of the queue. I also effectively handled outliers, ensuring the accuracy of the data used for analysis.
- My thesis culminated in the development of a queueing theory model. This model enabled me to identify and interpret trends and patterns in the data pipeline, ultimately aiming to optimize identified bottlenecks and enhance overall performance.

<!-- ### project 2 -->

<!--
**JAMota/JAMota** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
