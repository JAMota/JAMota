# Data Engineer

#### Technical Skills: Python, SAP BI, Power BI, PL/SQ, R, Apache Kafka

## Work Experience
**Portfolio Analyst @ European Investment Bank (_March 2020 - August 2020_)**
- Led the development of dynamic dashboards in SAP Business Intelligence, significantly enhancing project evaluation and documentation efficiency, particularly during end-of-month peaks. 
-	Ensured proper documentation of project usage guidelines, mitigating the impact of team member absence and providing a solid foundation for future reference and development.
-	Implemented dynamic dashboards that expedited the project assessment process, reducing workload and enabling the team to consistently meet targets and standards while maintaining operational efficiency. 
-	Achieved a 25% increase in project evaluation and documentation efficiency, demonstrating the effectiveness of the newly developed dashboards.


**Tech Support Systems Analyst @ CPS (_February 2022 - July 2022_)**
-	Delivered comprehensive technical support services to our valued clients, resolving a wide range of IT-related issues, encompassing hardware, software, server, and network challenges. 
-	Maintained and optimized clients' systems, servers, and networks, maximizing performance and security, with meticulous documentation of support activities, allowing for effective tracking and transparency. 
-	Actively contributed to our IT support team's knowledge sharing and cooperative work culture.

## Education					       		
- M.S., Data Science and Statistics	| University of Exeter (_December 2023_)	 			        		
- B.S., Computer Science | Polytechnic of Leiria (_July 2022_)

## Projects
### Queueing theory for analysis and improvement of data pipelines

[Master Thesis](https://github.com/JAMota/Applied-Data-Science-and-Statistics/tree/main/Thesis)

- For my master thesis, I developed a complex data pipeline from scratch, employing queueing theory for analysis. I utilized an SQLite database to securely store all generated data, ensuring efficient retrieval and manipulation of the data.
- To facilitate data flow across various servers, I implemented a multi-step data pipeline using Apache Kafka in the Azure cloud. This allowed for seamless data generation based on the data collection at each server, achieved through Python scripting.
- Following the ETL (Extract, Transform, Load) practice, I extracted, wrangled, normalized, and cleaned all data from each step of the queue. I also effectively handled outliers, ensuring the accuracy of the data used for analysis.
- My thesis culminated in the development of a queueing theory model. This model enabled me to identify and interpret trends and patterns in the data pipeline, ultimately aiming to optimize identified bottlenecks and enhance overall performance.

<!-- ### project 2 -->

<!--
**JAMota/JAMota** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
